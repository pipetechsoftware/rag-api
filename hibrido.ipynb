{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williancae/Documents/pipetech/lambda-RAG/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_qdrant import Qdrant\n",
    "from docling.document_converter import DocumentConverter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import Qdrant as QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from fastembed import TextEmbedding\n",
    "from fastembed import SparseTextEmbedding\n",
    "from fastembed import LateInteractionTextEmbedding\n",
    "from typing import List\n",
    "\n",
    "QDRANT_URL: str = (\n",
    "    \"https://87f833ae-d2cf-4e04-b838-eb649ec8845f.us-east4-0.gcp.cloud.qdrant.io:6333\"\n",
    ")\n",
    "QDRANT_KEY: str = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIiwiZXhwIjoxNzQ3MTU5MTkyfQ.8e-ojt9M0AKaW2AQ3iR4ldpyb1JFGlixgOZjWsUBjcI\"\n",
    "OPENAI_API_KEY: str = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QDRANT_CLIENT = QdrantClient(url=QDRANT_URL, api_key=QDRANT_KEY)\n",
    "EMBEDDINGS = OpenAIEmbeddings(model=\"text-embedding-ada-002\",api_key=OPENAI_API_KEY)\n",
    "\n",
    "DENSE_EMBEDDINGS_MODEL = TextEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "SPARSE_EMBEDDINGS_MODEL = SparseTextEmbedding(model_name=\"Qdrant/bm25\")\n",
    "LATE_INTERACTION_MODEL = LateInteractionTextEmbedding(model_name=\"colbert-ir/colbertv2.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = 'noemi'\n",
    "DOCUMENT_PATH = 'mais-esperto-que-o-diabo.pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iniciar extração com Docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docling\n",
    "\n",
    "doc_converter = DocumentConverter()\n",
    "document_text = doc_converter.convert(DOCUMENT_PATH ).document.export_to_text()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1263, which is longer than the specified 1000\n",
      "Created a chunk of size 1037, which is longer than the specified 1000\n",
      "Created a chunk of size 1045, which is longer than the specified 1000\n",
      "Created a chunk of size 1018, which is longer than the specified 1000\n",
      "Created a chunk of size 1004, which is longer than the specified 1000\n",
      "Created a chunk of size 1378, which is longer than the specified 1000\n",
      "Created a chunk of size 1341, which is longer than the specified 1000\n",
      "Created a chunk of size 1049, which is longer than the specified 1000\n",
      "Created a chunk of size 1014, which is longer than the specified 1000\n",
      "Created a chunk of size 1293, which is longer than the specified 1000\n",
      "Created a chunk of size 1214, which is longer than the specified 1000\n",
      "Created a chunk of size 1007, which is longer than the specified 1000\n",
      "Created a chunk of size 1285, which is longer than the specified 1000\n",
      "Created a chunk of size 1853, which is longer than the specified 1000\n",
      "Created a chunk of size 1266, which is longer than the specified 1000\n",
      "Created a chunk of size 1258, which is longer than the specified 1000\n",
      "Created a chunk of size 1259, which is longer than the specified 1000\n",
      "Created a chunk of size 1773, which is longer than the specified 1000\n",
      "Created a chunk of size 1362, which is longer than the specified 1000\n",
      "Created a chunk of size 1242, which is longer than the specified 1000\n",
      "Created a chunk of size 1735, which is longer than the specified 1000\n",
      "Created a chunk of size 1318, which is longer than the specified 1000\n",
      "Created a chunk of size 1713, which is longer than the specified 1000\n",
      "Created a chunk of size 1479, which is longer than the specified 1000\n",
      "Created a chunk of size 1209, which is longer than the specified 1000\n",
      "Created a chunk of size 3094, which is longer than the specified 1000\n",
      "Created a chunk of size 1450, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100) \n",
    "split_text: List[str] = text_splitter.split_text(text=document_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "dense_embeddings = list(DENSE_EMBEDDINGS_MODEL.passage_embed(document_text))\n",
    "\n",
    "print(len(list(dense_embeddings)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422\n"
     ]
    }
   ],
   "source": [
    "sparse_embeddings = list(SPARSE_EMBEDDINGS_MODEL.passage_embed(document_text))\n",
    "print(len(list(sparse_embeddings)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Late interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "late_interaction_embeddings = list(LATE_INTERACTION_MODEL.passage_embed(document_text))\n",
    "print(len(list(late_interaction_embeddings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(late_interaction_embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### connect with qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "QDRANT_CLIENT = QdrantClient(url=QDRANT_URL, api_key=QDRANT_KEY)\n",
    "\n",
    "if not QDRANT_CLIENT.collection_exists(COLLECTION_NAME):\n",
    "    QDRANT_CLIENT.create_collection(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        vectors_config={\n",
    "            \"all-MiniLM-L6-v2\": models.VectorParams(\n",
    "            size=384,\n",
    "            distance=models.Distance.COSINE,\n",
    "            ),\n",
    "            \"colbertv2.0\": models.VectorParams(\n",
    "                size=128,\n",
    "                distance=models.Distance.COSINE,\n",
    "                multivector_config=models.MultiVectorConfig(\n",
    "                    comparator=models.MultiVectorComparator.MAX_SIM,\n",
    "                )\n",
    "            ),\n",
    "        },\n",
    "        sparse_vectors_config={\n",
    "            \"bm25\": models.SparseVectorParams(\n",
    "                modifier=models.Modifier.IDF,\n",
    "            )\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_embedding = list(DENSE_EMBEDDINGS_MODEL.passage_embed(document_text))[0]\n",
    "sparse_embedding = list(SPARSE_EMBEDDINGS_MODEL.passage_embed(document_text))[0]\n",
    "late_interaction_embedding = list(LATE_INTERACTION_MODEL.passage_embed(document_text))[0]\n",
    "\n",
    "\n",
    "i = 1\n",
    "QDRANT_CLIENT.upload_points(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=i,\n",
    "            vector={\n",
    "                \"all-MiniLM-L6-v2\": dense_embedding.tolist(),       \n",
    "                \"bm25\": sparse_embedding.as_object(),\n",
    "                \"colbertv2.0\": late_interaction_embedding.tolist()   \n",
    "            },\n",
    "            payload={\n",
    "                \"_id\": i,\n",
    "                \"title\": \"mais-esperto-que-o-diabo\",\n",
    "                \"text\": document_text\n",
    "            }\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
